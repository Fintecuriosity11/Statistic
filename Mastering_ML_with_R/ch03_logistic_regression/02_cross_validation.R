################################################################################################################

#(주의) ->  순차적으로 코드를 실행하는 것을 권함!

################################################################################################################

#교차검증(cross-validation)을 하는 목적은 테스트 세트를 이용한 예측을 향상시키고 과적합의 위험을 최소화하는 것.
#K-겹 교차 검증에서는 데이터 세트를 같은 크기를 갖는 조각으로 K등분.
#알고리즘은 k-세트 중에 1개의 세트를 번갈아 제외하며 학습

#하나의 모형은 제외한 나머지 "K-1"개의 조각으로 적합화 하여 만듬.
#예측값은 이 모형에서 제외했던 세트를 테스트 세트로 얻음.

#오류 최소화를 위해 결과들을 평균 내어 가장 적합한 피처 선택. 
#리브-원-아웃-교차 검증 실행 가능=데이터 개수가 N개일 때, 각각 1개씩 제외하며 N회 반복하는 교차 검증.
#시뮬레이션을 해보면, LOOCV 방법은 평균 추정값의 분산이 높게 나타남.

#결론은 ML 엔지니어는 K-겹 교차 검증에서 K를 5나 10으로 정하도록 권장.

################################################################################################################

#로지스틱 회귀를 위한 교차 검증을 자동으로 해주는 R패키지 bestglm() 사용
#이 패키지는 선형회귀 때 사용했던 leaps 패키지에 종속적, bestglm()을 불러오면 leaps 로딩
#패키지를 불러온 후 앞에서 결과값을 0과 1로 코드화.

#변수형이 요인(factor)로 남아있으면 작동 X
#또한 이패키지를 사용하기 위한 또 다른 조건은 결과값 y가 맨 마지막 칼럼에 와야함. 불필요한 칼럼은 삭제.

################################################################################################################


install.packages("bestglm")

library(InformationValue)
library(bestglm)

#새로운 데이터프레임 생성.

X <- train[, 1:9]
Xy <- data.frame(cbind(X, trainY))

################################################################################################################


#교차검증을 위한 코드.

#첫 번째 인자인 Xy=Xy는 앞서 이 함수를 위해 포맷했던 데이터프레임을 가르킴.
#IC="CV"는 패키지에게 정보 기준으로 교차검증법을 쓰겠다는 정보를 건넴.

#CVArgs는 교차 검증을 위한 인자로, 우리가 주고 싶은 값 지정.
#HTF 방법은 K-겹 교차 검증법 의미, 이어 나타나는 K=10인자는 몇 겹인지 알려주는 것이며, REP=1은 무작위 폴드를 단 1회만 수행

#분석을 시행한 후에는 think, u.size, nucl의 3 피처를 포함하는 Best Model이 결과로 나타남.
#Morgan-Tartar search라는 문장은 단순하고 철저하게 탐색 가능한 모든 서브 세트에 관해 실시.

################################################################################################################


bestglm(Xy = Xy, IC="CV", CVArgs = list(Method="HTF", K=10, REP=1), family = binomial)

#위에서 구한 피처를 glm()에 넣고, 테스트 세트에 관해 모형이 얼마나 잘 작동하는지 확인.
#이렇게 작업을 한 단계 더 하는 이유는, predict()함수는 bestglm()과 연동이 되지 않기때문임.

reduce.fit <- glm(class ~ thick + u.size + nucl, family = binomial, data = train)

#테스트 세트에 관해 예측된 식별값과 실제값 비교.

test.cv.probs <- predict(reduce.fit, newdata = test, type = "response")


misClassError(testY, test.cv.probs) #misClassError()함수는 InformationValue 패키지 로딩 후 사용 가능.

confusionMatrix(testY, test.cv.probs)

#축소된 모형(reduced model)은 모든 피처를 포함하는 완전 모형(full model)에 비하면 약간 덜 정확한 것으로 추정.
#정보 기준을 BIC로 바꾼 후 bestglm()패키지 사용.

bestglm(Xy = Xy, IC = "BIC", family = binomial)

#4개의 피처가 가능한 모든 서브 세트 모형 중에서 최소의 BIC를 제공.
#4개의 피처로 만든 모형으로 test set의 예측률 확인.

bic.fit <- glm(class ~ thick + adhsn + nucl + n.nuc, family = binomial, data = train)

test.bic.probs <- predict(bic.fit, newdata = test, type = "response")

misClassError(testY, test.bic.probs)

confusionMatrix(testY, test.bic.probs)

#모형에서는 5개의 오류만 있었음.
#이때 둘 중어떤 모형이 더 나은가? 라고 물었다면.
#가장 해석하기 좋은 모형이 좋은 모형이라고 함.

#새로운 랜덤화 및 훈련 세트와 테스트 세트를 나누는 비율을 다르게 하는 방법으로, 완전히 다른 분석을 시행할 수도 있음.
